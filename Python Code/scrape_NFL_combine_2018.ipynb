{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_links(pageHTML,linkList):\n",
    "    soup = BeautifulSoup(pageHTML, 'lxml')\n",
    "    playerTD = soup.findAll('td', {'class':'name selected'})\n",
    "    for player in playerTD:\n",
    "        link = player.find('a')['href'].encode('ascii','ignore').strip()\n",
    "        linkList.append(link)\n",
    "    return linkList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Use the instructions found here to install PhantomJS on Ubuntu: \n",
    "#       https://www.vultr.com/docs/how-to-install-phantomjs-on-ubuntu-16-04\n",
    "\n",
    "# Open a PhantomJS web browser and direct it to the DEA's dropbox search page\n",
    "browser = webdriver.PhantomJS()\n",
    "browser.get('http://www.nfl.com/combine/tracker#day=fullresults')\n",
    "browser.implicitly_wait(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navButtonRow = soup.findAll('li', {'class':'page'})\n",
    "#test = xpath_soup(navButtonRow[1])\n",
    "#elm = browser.find_element_by_xpath(test)\n",
    "#elm = browser.find_element_by_xpath('/html/body/div[4]/div[3]/div/div[2]/div[1]/div[2]/div[1]/div[2]/table/tfoot/tr/td/ol/li[4]')\n",
    "\n",
    "# Storage container for all player links\n",
    "urlList = []\n",
    "\n",
    "# Extract the original page information\n",
    "html = browser.page_source\n",
    "urlList = scrape_player_links(html, urlList)\n",
    "#urlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the navigation bar at the bottom of the page for navigation\n",
    "navBar = browser.find_elements_by_class_name('page')\n",
    "pageCount = len(navBar)\n",
    "\n",
    "# Advance to the next page (page 2)\n",
    "buttons = browser.find_elements_by_class_name('page')\n",
    "buttons[1].click()\n",
    "\n",
    "# Advance to the next page and repeat the scraping process (for all remaining pages)\n",
    "for page in range(2,pageCount):\n",
    "    html = browser.page_source\n",
    "    urlList = scrape_player_links(html,urlList)\n",
    "    buttons = browser.find_elements_by_class_name('page')\n",
    "    buttons[page].click()\n",
    "    \n",
    "# Grab the last page (since the loop won't iterate through the final page)\n",
    "html = browser.page_source\n",
    "urlList = scrape_player_links(html,urlList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urlList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the player links, we can access each individual player page to obtain detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n"
     ]
    }
   ],
   "source": [
    "playerInfoList = []\n",
    "playerCount = 0\n",
    "\n",
    "headers = {\"User-agent\":\n",
    "           \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36\"}\n",
    "\n",
    "for link in urlList:\n",
    "    r = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "    # Basic info is react_id = 153\n",
    "    #basicInfo = soup.find('div', {'data-reactid':'153'})\n",
    "    basicInfo = soup.findAll('script')[5].text\n",
    "    basicInfo = basicInfo.split('__INITIAL_DATA__ = ')[1]\n",
    "    basicInfo = basicInfo.split(';\\n  ')[0]\n",
    "    basicInfo = basicInfo.encode('ascii','ignore')\n",
    "    basicInfo = basicInfo.replace('\\\\\"','')\n",
    "    \n",
    "    temp = json.loads(basicInfo)\n",
    "    \n",
    "    player = {}\n",
    "    \n",
    "    player['picURL'] = temp['instance']['prospect']['headshot']['asset']['url']                  # pictureURL\n",
    "    player['nameFirst'] = temp['instance']['prospect']['person']['firstName']                    # first name\n",
    "    player['nameLast'] = temp['instance']['prospect']['person']['lastName']                      # last name\n",
    "    player['college'] = temp['instance']['prospect']['currentCollege']                           # college\n",
    "    player['conference'] = temp['instance']['prospect']['collegeConference']                     # conference\n",
    "    player['position'] = temp['instance']['prospect']['position']                                # position\n",
    "    player['homeCity'] = temp['instance']['prospect']['person']['hometown']                      # hometown-city\n",
    "    player['homeState'] = temp['instance']['prospect']['homeState']                              # hometown-state\n",
    "    player['schoolYear'] = temp['instance']['prospect']['collegeClass']                          # year of school\n",
    "    player['height'] = temp['instance']['prospect']['height']                                    # height\n",
    "    player['weight'] = temp['instance']['prospect']['weight']                                    # weight\n",
    "    player['lengthArm'] = temp['instance']['prospect']['armLength']                              # arm length\n",
    "    player['lengthHand'] = temp['instance']['prospect']['handSize']                              # hand length\n",
    "    player['grade'] = temp['instance']['prospect']['grade']                                      # prospect grade\n",
    "    player['combineID'] = temp['instance']['prospect']['combineData']['combineNumber']           # combine ID\n",
    "    player['combine40'] = temp['instance']['prospect']['combineData']['fortyYardDashResult']     # 40 yard dash\n",
    "    player['combineBench'] = temp['instance']['prospect']['combineData']['benchResult']          # bench press\n",
    "    player['combineVert'] = temp['instance']['prospect']['combineData']['verticalJumpResult']    # vertical jump\n",
    "    player['combineBroad'] = temp['instance']['prospect']['combineData']['broadJumpResult']      # broad jump\n",
    "    player['combineCone'] = temp['instance']['prospect']['combineData']['threeConeDrillResult']  # 3 Cone Drill\n",
    "    player['combine20'] = temp['instance']['prospect']['combineData']['twentyYardShuttleResult'] # 20 yard shuttle run\n",
    "    player['combine60'] = temp['instance']['prospect']['combineData']['sixtyYardShuttleResult']  # 60 yard shuttle run   \n",
    "    player['overview'] = temp['instance']['prospect']['overview']                                # player Overview\n",
    "    player['sources'] = temp['instance']['prospect']['sourcesTellUs']                            # info from sources\n",
    "    player['strengths'] = temp['instance']['prospect']['strengths']                              # player strengths\n",
    "    player['weaknesses'] = temp['instance']['prospect']['weaknesses']                            # player weaknesses\n",
    "    player['bottomLine'] = temp['instance']['prospect']['bottomLine']                            # player bottom-line\n",
    "    player['nflComp'] = temp['instance']['prospect']['nflComparison']                            # NFL comparison\n",
    "    player['projection'] = temp['instance']['prospect']['draftProjection']                       # projected draft status\n",
    "    player['profileAuthor'] = temp['instance']['prospect']['profileAuthor']                      # Profile Author\n",
    "    \n",
    "    playerInfoList.append(player)\n",
    "    playerCount+=1\n",
    "    if (playerCount%25==0): print(playerCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some values for hometown-City capture the state as well (let's fix this)\n",
    "for player in playerInfoList:\n",
    "    if (isinstance(player['homeCity'], basestring)):\n",
    "        if ', ' in  player['homeCity']: \n",
    "            oldCity = player['homeCity']\n",
    "            player['homeCity'] = oldCity.split(', ')[0]\n",
    "            player['homeState'] = oldCity.split(', ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data set\n",
    "filename = 'combine_2018.json'\n",
    "with open(filename, 'wt') as out:\n",
    "    json.dump(playerInfoList, out, sort_keys=True, indent=4, separators=(',', ': ')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
